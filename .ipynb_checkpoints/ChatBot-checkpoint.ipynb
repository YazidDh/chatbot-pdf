{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d519b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA,  ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "038415b4-def5-4e49-9072-d774038e5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi language chatbot \n",
    "\n",
    "def load_db(file, chain_type, k):\n",
    "    print(\"loading pdf ...\")\n",
    "    # load documents\n",
    "    loader = PyPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "    # split documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    # define embedding\n",
    "    #embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text:latest\")\n",
    "    # create vector database from data\n",
    "    db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "    # define retriever\n",
    "    retriever = db.as_retriever(\n",
    "    search_type=\"similarity\", \n",
    "    search_kwargs={\"k\": k, \"score_threshold\": 0.75}  \n",
    "    )\n",
    "    \"\"\"retriever = db.as_retriever(\n",
    "    search_type=\"similarity\", \n",
    "    search_kwargs={\"k\": k, \"neighbors\": 3, \"iterations\": 2}\n",
    "    )\"\"\"\n",
    "    # create a chatbot chain. Memory is managed externally.\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm =  OllamaLLM(model=\"qwen2.5:1.5b\"),\n",
    "        chain_type=chain_type, \n",
    "        retriever=retriever, \n",
    "        return_source_documents=True,\n",
    "        return_generated_question=True,\n",
    "    )\n",
    "    \n",
    "    return qa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4bb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pdf ...\n",
      "User\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  what are the machine learning algorithms discussed ? \n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start_load = time.time()\n",
    "qa = load_db(\"MachineLearning-Lecture01.pdf\", \"stuff\", 4)\n",
    "chat_history = []\n",
    "while True:\n",
    "    print(\"User\")\n",
    "    question = input()\n",
    "    if question == \"q\":\n",
    "        break\n",
    "    res_time = time.time()\n",
    "    bot_response = qa({\"question\": question, \"chat_history\": chat_history})    \n",
    "    #bot_response = qa({\"question\": \"Réponds en français : \" + question, \"chat_history\": chat_history})    \n",
    "    print()\n",
    "    \"\"\"print(\"Retrieved documents:\")\n",
    "    for doc in bot_response.get(\"source_documents\", []):\n",
    "        print(doc.page_content)\"\"\"\n",
    "    chat_history.append((question, bot_response[\"answer\"]))\n",
    "    print()\n",
    "    print(\"chatbot: \" +  bot_response[\"answer\"])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ab73b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7fd1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e41f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
